{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qp590tgEpTJ_"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaP2FTa0n1Xv"
   },
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Tr0Wq2slgcoM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prophet\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cpd0vWJkphx7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_21yRsVPpZxR"
   },
   "source": [
    "# **Descarga de los datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZpTfqUQ8nz6K"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./UH_2023_TRAIN.txt', sep = \"|\")\n",
    "ETO_dataset = pd.read_csv('./DATOS_ETO.TXT', sep = \"|\")\n",
    "METEO_dataset = pd.read_csv('./DATOS_METEO.TXT', sep = \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkkMmpkjx4f0"
   },
   "source": [
    "## DATASET TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oMW2iJuQx4f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_original = train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cbiVLelNx4f5"
   },
   "outputs": [],
   "source": [
    "train[\"MODO\"] = train[\"MODO\"]-1 #Vemos que modo varia entre 2 y 1, le restamos para pasarlo a binario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnxcNnuKpIaG"
   },
   "source": [
    "#### ALTITUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ttv_JQt6UolX"
   },
   "outputs": [],
   "source": [
    "train[\"ALTITUD\"] = train[\"ALTITUD\"].str[:3].apply(pd.to_numeric)\n",
    "altitud_actualizada = train.sort_values([\"ID_ESTACION\",\"ID_ZONA\"],\n",
    "                                        na_position='last')['ALTITUD'].fillna(method='ffill').fillna(method=\"bfill\")\n",
    "train[\"ALTITUD\"] = altitud_actualizada\n",
    "del altitud_actualizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXEL0OPcpIaH"
   },
   "source": [
    "#### SUPERFICIE 20/21/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g9gbRgVA3Oi9"
   },
   "outputs": [],
   "source": [
    "corregir_superficie_20 = train[train[\"CAMPAÑA\"] == 20]\n",
    "corregir_superficie_20 = pd.get_dummies(corregir_superficie_20, columns = [\"ID_ESTACION\",\"VARIEDAD\"])\n",
    "corregir_superficie_20[\"SUPERFICIE\"].replace(0, np.nan, inplace=True)\n",
    "corregir_superficie_20.drop([\"CAMPAÑA\",\"ID_FINCA\",\"COLOR\",\"TIPO\",\"ID_ZONA\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J_AZYVhYGR-f"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 2))\n",
    "scaler.fit(corregir_superficie_20[\"PRODUCCION\"].to_numpy().reshape(-1, 1))\n",
    "corregir_superficie_20[\"PRODUCCION\"] = scaler.transform(corregir_superficie_20[\"PRODUCCION\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(corregir_superficie_20[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "corregir_superficie_20[\"ALTITUD\"]= scaler2.transform(corregir_superficie_20[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 3)\n",
    "corregir_superficie_20[\"SUPERFICIE\"] = imputer.fit_transform(corregir_superficie_20)[:,2]\n",
    "\n",
    "corregir_superficie_20[\"PRODUCCION\"] = scaler.inverse_transform(corregir_superficie_20[\"PRODUCCION\"].to_numpy().reshape(-1,1))\n",
    "corregir_superficie_20[\"ALTITUD\"] = scaler2.inverse_transform(corregir_superficie_20[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "train.loc[train.CAMPAÑA == 20, 'SUPERFICIE'] = corregir_superficie_20[\"SUPERFICIE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q_ZBCGrKpIaI"
   },
   "outputs": [],
   "source": [
    "corregir_superficie_21 = train[train[\"CAMPAÑA\"] == 21]\n",
    "corregir_superficie_21 = corregir_superficie_21.drop([\"CAMPAÑA\",\"ID_FINCA\",\"ID_ZONA\",\"TIPO\",\"COLOR\"], axis = 1)\n",
    "corregir_superficie_21 = pd.get_dummies(corregir_superficie_21, columns=[\"ID_ESTACION\",\"VARIEDAD\"])\n",
    "corregir_superficie_21[\"SUPERFICIE\"].replace(0, np.nan, inplace=True)\n",
    "\n",
    "scaler.fit(corregir_superficie_21[\"PRODUCCION\"].to_numpy().reshape(-1,1))\n",
    "corregir_superficie_21[\"PRODUCCION\"] = scaler.transform(corregir_superficie_21[\"PRODUCCION\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "scaler2.fit(corregir_superficie_21[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "corregir_superficie_21[\"ALTITUD\"] = scaler2.transform(corregir_superficie_21[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "corregir_superficie_21[\"SUPERFICIE\"] = imputer.fit_transform(corregir_superficie_21)[:,2]\n",
    "\n",
    "corregir_superficie_21[\"PRODUCCION\"] = scaler.inverse_transform(corregir_superficie_21[\"PRODUCCION\"].to_numpy().reshape(-1,1))\n",
    "corregir_superficie_21[\"ALTITUD\"] = scaler2.inverse_transform(corregir_superficie_21[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "train.loc[train.CAMPAÑA == 21, 'SUPERFICIE'] = corregir_superficie_21[\"SUPERFICIE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "B-XM0Y0gpIaJ"
   },
   "outputs": [],
   "source": [
    "corregir_superficie_21[\"ID_FINCA\"] = train[train[\"CAMPAÑA\"] == 21][\"ID_FINCA\"]\n",
    "corregir_superficie_21[\"VARIEDAD\"] = train[train[\"CAMPAÑA\"] == 21][\"VARIEDAD\"]\n",
    "\n",
    "\n",
    "corregir_superficie_20[\"ID_FINCA\"] = train[train[\"CAMPAÑA\"] == 20][\"ID_FINCA\"]\n",
    "corregir_superficie_20[\"VARIEDAD\"] = train[train[\"CAMPAÑA\"] == 20][\"VARIEDAD\"]\n",
    "keys = list(corregir_superficie_20[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\"]].columns.values)\n",
    "i1 = corregir_superficie_20.set_index(keys).index\n",
    "i2 = corregir_superficie_21.set_index(keys).index\n",
    "\n",
    "\n",
    "igualtats_20 = corregir_superficie_20[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"SUPERFICIE\"]][i1.isin(i2)]\n",
    "igualtats_21 = corregir_superficie_21[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"SUPERFICIE\"]][i2.isin(i1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cg_8hB8V3iC-"
   },
   "outputs": [],
   "source": [
    "igualtats_20[\"SUPERFICIE_21\"] = train[train[\"CAMPAÑA\"]==21][\"SUPERFICIE\"][i2.isin(i1)].values\n",
    "\n",
    "igualtats_20[\"SUPERFICIE\"] = igualtats_20[[\"SUPERFICIE\",\"SUPERFICIE_21\"]].mean(axis=1)\n",
    "igualtats_21[\"SUPERFICIE\"] = igualtats_20[\"SUPERFICIE\"].values\n",
    "train.loc[igualtats_20.index, \"SUPERFICIE\"] = igualtats_20[\"SUPERFICIE\"]\n",
    "train.loc[igualtats_21.index, \"SUPERFICIE\"] = igualtats_21[\"SUPERFICIE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I3tKgGjJ3ujH"
   },
   "outputs": [],
   "source": [
    "corregir_superficie_22 = train[train[\"CAMPAÑA\"] == 22]\n",
    "corregir_superficie_22 = corregir_superficie_22[corregir_superficie_22[\"SUPERFICIE\"] == 0]\n",
    "keys = list(corregir_superficie_22[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\"]].columns.values)\n",
    "i1 = corregir_superficie_22.set_index(keys).index\n",
    "i2 = igualtats_20.set_index(keys).index\n",
    "corregir_superficie_22[\"SUPERFICIE\"] = (igualtats_20[i2.isin(i1)][\"SUPERFICIE\"]).values\n",
    "train.loc[corregir_superficie_22.index, 'SUPERFICIE'] = corregir_superficie_22[\"SUPERFICIE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPDdTWYbpIaK"
   },
   "source": [
    "#### OTRAS SUPERFICIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mj5HeBWp34GE"
   },
   "outputs": [],
   "source": [
    "campaña_21 = train[train[\"CAMPAÑA\"] == 21] \n",
    "campaña_20 = train[train[\"CAMPAÑA\"] == 20] \n",
    "campaña_15 = train[train[\"CAMPAÑA\"] == 15] \n",
    "campaña_16 = train[train[\"CAMPAÑA\"] == 16] \n",
    "campaña_17 = train[train[\"CAMPAÑA\"] == 17] \n",
    "campaña_18 = train[train[\"CAMPAÑA\"] == 18] \n",
    "campaña_19 = train[train[\"CAMPAÑA\"] == 19] \n",
    "campaña_14 = train[train[\"CAMPAÑA\"] == 14] \n",
    "\n",
    "keys = list(train[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"ID_ESTACION\",\"TIPO\"]].columns.values)\n",
    "i_14 = campaña_14.set_index(keys).index\n",
    "i_20 = campaña_20.set_index(keys).index\n",
    "i_21 = campaña_21.set_index(keys).index\n",
    "i_15 = campaña_15.set_index(keys).index\n",
    "i_16 = campaña_16.set_index(keys).index\n",
    "i_17 = campaña_17.set_index(keys).index\n",
    "i_18 = campaña_18.set_index(keys).index\n",
    "i_19 = campaña_19.set_index(keys).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xsfQClVa35_j"
   },
   "outputs": [],
   "source": [
    "sub_train = train[train[\"CAMPAÑA\"] < 22].copy()\n",
    "terrenos = sub_train[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"ID_ESTACION\",\"TIPO\"]].drop_duplicates()\n",
    "terrenos = terrenos[(terrenos.ID_ESTACION != 1) & (terrenos.ID_ESTACION != 13) & (terrenos.ID_ESTACION != 0)\n",
    "                   & (terrenos.ID_ESTACION != 17) & (terrenos.ID_ESTACION != 11) & (terrenos.ID_ESTACION != 4)\n",
    "                    & (terrenos.ID_ESTACION != 2) & (terrenos.ID_ESTACION != 6) & (terrenos.ID_ESTACION != 8)]\n",
    "i_terrenos = terrenos.set_index(keys).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3FPE0-T84Bzz"
   },
   "outputs": [],
   "source": [
    "#14   \n",
    "terrenos = terrenos.merge(campaña_14[i_14.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_14\"})\n",
    "#15\n",
    "terrenos = terrenos.merge(campaña_15[i_15.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_15\"})\n",
    "#16\n",
    "terrenos = terrenos.merge(campaña_16[i_16.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_16\"})\n",
    "#17\n",
    "terrenos = terrenos.merge( campaña_17[i_17.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_17\"})\n",
    "#18\n",
    "terrenos = terrenos.merge( campaña_18[i_18.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_18\"})\n",
    "#19\n",
    "terrenos = terrenos.merge(campaña_19[i_19.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_19\"})\n",
    "#20\n",
    "terrenos = terrenos.merge( campaña_20[i_20.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','SUPERFICIE','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_20\", \"SUPERFICIE\":\"SUPERFICIE_20\"})\n",
    "#21\n",
    "terrenos = terrenos.merge( campaña_21[i_21.isin(i_terrenos)][['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','PRODUCCION','SUPERFICIE','TIPO']], how='left',on = ['ID_FINCA','VARIEDAD','MODO','ID_ESTACION','TIPO'])\n",
    "terrenos = terrenos.rename(columns={\"PRODUCCION\":\"PRODUCCION_21\",\"SUPERFICIE\":\"SUPERFICIE_21\"})\n",
    "terrenos = terrenos.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "50bw45dP4Opa"
   },
   "outputs": [],
   "source": [
    "aux = terrenos.copy()\n",
    "aux[\"DIF_14_20\"] = 0\n",
    "aux[\"DIF_15_20\"] = 0\n",
    "aux[\"DIF_16_20\"] = 0\n",
    "aux[\"DIF_17_20\"] = 0\n",
    "aux[\"DIF_18_20\"] = 0\n",
    "aux[\"DIF_19_20\"] = 0\n",
    "aux[\"DIF_14_21\"] = 0\n",
    "aux[\"DIF_15_21\"] = 0\n",
    "aux[\"DIF_16_21\"] = 0\n",
    "aux[\"DIF_17_21\"] = 0\n",
    "aux[\"DIF_18_21\"] = 0\n",
    "aux[\"DIF_19_21\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3dDII7apIaM"
   },
   "source": [
    "Test estadístico de igualdad de varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PykegD9N4UO-"
   },
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "\n",
    "for i in np.unique(terrenos.ID_ESTACION.values):\n",
    "    prod_20 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_20\"]\n",
    "    prod_21 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_21\"]\n",
    "\n",
    "    #CAMPAÑA 14\n",
    "    prod_14 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_14\"]\n",
    "    if(scipy.stats.levene(prod_14[prod_14!=0],prod_20[prod_20!=0]).pvalue>0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_14\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf]=0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20!=0] - np.mean(diferencias_20[diferencias_20!=0]))/np.std(diferencias_20[diferencias_20!=0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_14_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "        \n",
    "    if(scipy.stats.levene(prod_14[prod_14!=0],prod_21[prod_21!=0]).pvalue>0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_14\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf]=0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21!=0] - np.mean(diferencias_21[diferencias_21!=0]))/np.std(diferencias_21[diferencias_21!=0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_14_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "    \n",
    "    #CAMPAÑA 15\n",
    "    prod_15 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_15\"]\n",
    "    if(scipy.stats.levene(prod_15[prod_15 != 0],prod_20[prod_20 != 0]).pvalue > 0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_15\"] / terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf] = 0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20 != 0] - np.mean(diferencias_20[diferencias_20 != 0])) / np.std(diferencias_20[diferencias_20 != 0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_15_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "    \n",
    "    \n",
    "    if(scipy.stats.levene(prod_15[prod_15!=0],prod_21[prod_21!=0]).pvalue > 0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_15\"] / terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf] = 0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21 != 0] - np.mean(diferencias_21[diferencias_21 != 0]))/np.std(diferencias_21[diferencias_21 != 0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_15_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "    \n",
    "    #CAMPAÑA 16\n",
    "    prod_16 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_16\"]\n",
    "    if(scipy.stats.levene(prod_16[prod_16!=0],prod_20[prod_20 != 0]).pvalue > 0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_16\"]/ terrenos[terrenos[\"ID_ESTACION\"] == i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf]=0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20!=0] - np.mean(diferencias_20[diferencias_20!=0]))/np.std(diferencias_20[diferencias_20!=0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_16_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "    \n",
    "    if(scipy.stats.levene(prod_16[prod_16!=0],prod_21[prod_21!=0]).pvalue>0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_16\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf]=0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21!=0] - np.mean(diferencias_21[diferencias_21!=0]))/np.std(diferencias_21[diferencias_21!=0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_16_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "   \n",
    "    #CAMPAÑA 17\n",
    "    prod_17 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_17\"]\n",
    "    if(scipy.stats.levene(prod_17[prod_17!=0],prod_20[prod_20!=0]).pvalue>0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_17\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf]=0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20!=0] - np.mean(diferencias_20[diferencias_20!=0]))/np.std(diferencias_20[diferencias_20!=0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_17_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "    \n",
    "    \n",
    "    if(scipy.stats.levene(prod_17[prod_17!=0],prod_21[prod_21!=0]).pvalue>0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_17\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf]=0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21!=0] - np.mean(diferencias_21[diferencias_21!=0]))/np.std(diferencias_21[diferencias_21!=0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_17_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "    \n",
    "    #CAMPAÑA 18\n",
    "    prod_18 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_18\"]\n",
    "    if(scipy.stats.levene(prod_18[prod_18!=0],prod_20[prod_20!=0]).pvalue>0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_18\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf]=0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20!=0] - np.mean(diferencias_20[diferencias_20!=0]))/np.std(diferencias_20[diferencias_20!=0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_18_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "    \n",
    "    \n",
    "    if(scipy.stats.levene(prod_18[prod_18!=0],prod_21[prod_21!=0]).pvalue>0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_18\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf]=0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21!=0] - np.mean(diferencias_21[diferencias_21!=0]))/np.std(diferencias_21[diferencias_21!=0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_18_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "    \n",
    "    #CAMPAÑA 19\n",
    "    prod_19 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_19\"]\n",
    "    if(scipy.stats.levene(prod_19[prod_19!=0],prod_20[prod_20!=0]).pvalue>0.2):\n",
    "        diferencias_20 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_19\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_20\"]\n",
    "        diferencias_20[diferencias_20 == inf]=0\n",
    "        normalizado_20 = (diferencias_20[diferencias_20!=0] - np.mean(diferencias_20[diferencias_20!=0]))/np.std(diferencias_20[diferencias_20!=0])\n",
    "        aux.loc[normalizado_20.index,\"DIF_19_20\"] = np.abs(normalizado_20.fillna(0))\n",
    "    \n",
    "    \n",
    "    if(scipy.stats.levene(prod_19[prod_19!=0],prod_21[prod_21!=0]).pvalue>0.2):\n",
    "        diferencias_21 = terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_19\"]/ terrenos[terrenos[\"ID_ESTACION\"]==i][\"PRODUCCION_21\"]\n",
    "        diferencias_21[diferencias_21 == inf]=0\n",
    "        normalizado_21 = (diferencias_21[diferencias_21!=0] - np.mean(diferencias_21[diferencias_21!=0]))/np.std(diferencias_21[diferencias_21!=0])\n",
    "        aux.loc[normalizado_21.index,\"DIF_19_21\"] = np.abs(normalizado_21.fillna(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "w9eOotEj4WQ-"
   },
   "outputs": [],
   "source": [
    "aux = aux.drop([\"PRODUCCION_14\",\"PRODUCCION_15\",\"PRODUCCION_16\",\"PRODUCCION_17\",\"PRODUCCION_18\",\"PRODUCCION_19\",\"PRODUCCION_20\",\"PRODUCCION_21\"],axis=1)\n",
    "#Evitamos reemplazar los 0 de MODO y TIPO por NaN\n",
    "aux_modos = aux[\"MODO\"] \n",
    "aux_tipo = aux[\"TIPO\"]\n",
    "aux.replace(0, np.nan, inplace=True)\n",
    "aux[\"MODO\"] = aux_modos\n",
    "aux[\"TIPO\"]= aux_tipo\n",
    "train_bo = train.copy()\n",
    "train_bo.SUPERFICIE.replace(0,np.nan,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mff-d4LhpIaN"
   },
   "source": [
    "68-95-99.7, optamos por el 68, es decir el 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RzqaBHAVkiyh"
   },
   "outputs": [],
   "source": [
    "for i in aux.values:\n",
    "    \n",
    "    if i[7] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 14) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[13]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 14) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]\n",
    "    if i[8] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 15) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[14]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 15) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]\n",
    "    if i[9] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 16) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[15]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 16) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]\n",
    "    if i[10] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 17) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[16]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 17) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]\n",
    "    if i[11] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 18) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[17]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 18) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]\n",
    "    if i[12] < 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 19) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[5]\n",
    "    elif i[18]< 1:\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == 19) & (train_bo.ID_FINCA == i[0]) & (train_bo.VARIEDAD == i[1])\n",
    "                    & (train_bo.MODO == i[2]) & (train_bo.ID_ESTACION == i[3]) \n",
    "                     & (train_bo.TIPO == i[4]), 'SUPERFICIE'] = i[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkyzEAadpIaN"
   },
   "source": [
    "Llenamos si la producción es muy parecida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fhn2vgh7kt6P"
   },
   "outputs": [],
   "source": [
    "superficie_null = train_bo[train_bo[\"SUPERFICIE\"].isnull()]\n",
    "superficie_nonull = train_bo[(train_bo[\"SUPERFICIE\"]>0) & (train_bo[\"CAMPAÑA\"]<22)]\n",
    "i_null = superficie_null.set_index(keys).index\n",
    "i_nonull = superficie_nonull.set_index(keys).index\n",
    "\n",
    "superficie_null=(superficie_null[i_null.isin(i_nonull)]).drop([\"ID_ZONA\",\"ALTITUD\",\"COLOR\"],axis=1)\n",
    "superficie_nonull=superficie_nonull[i_nonull.isin(i_null)].drop([\"CAMPAÑA\",\"ID_ZONA\",\"ALTITUD\",\"COLOR\"],axis=1)\n",
    "\n",
    "for i in superficie_null.values:    \n",
    "    prod_sup = superficie_nonull.loc[(superficie_nonull.ID_FINCA == i[1]) & (superficie_nonull.VARIEDAD == i[3])\n",
    "                    & (superficie_nonull.MODO == i[4]) & (superficie_nonull.ID_ESTACION == i[2]) \n",
    "                     & (superficie_nonull.TIPO == i[5]), [\"PRODUCCION\",\"SUPERFICIE\"]]\n",
    "    minimo = np.abs(prod_sup[\"PRODUCCION\"] - i[-1]).min() #Resultado mas parecido entre producción de superfície desconocida y conocida\n",
    "    index = np.argmin(np.abs(prod_sup[\"PRODUCCION\"] - i[-1]))\n",
    "    #Si la producción no ha variado en un 50% o la superfície es igual para todas las fincas y hay más de 3 casos, llenamos con esa superf´cie\n",
    "    if(minimo/prod_sup[\"PRODUCCION\"].values[index] < 0.6) or (((prod_sup[\"SUPERFICIE\"]).min() == prod_sup[\"SUPERFICIE\"].max()) and (len(prod_sup[\"SUPERFICIE\"])>3)):\n",
    "        train_bo.loc[(train_bo.CAMPAÑA == i[0]) &  (train_bo.ID_FINCA == i[1]) & (train_bo.VARIEDAD == i[3])\n",
    "                    & (train_bo.MODO == i[4]) & (train_bo.ID_ESTACION == i[2]) \n",
    "                     & (train_bo.TIPO == i[5]), 'SUPERFICIE'] = prod_sup[\"SUPERFICIE\"].values[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBh5MLjUpIaO"
   },
   "source": [
    "Llenamos con superficies del 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FPjuAFHzk2Tf"
   },
   "outputs": [],
   "source": [
    "superficie_null = train_bo[train_bo[\"SUPERFICIE\"].isnull()]\n",
    "superficie_nonull = train_bo[(train_bo[\"SUPERFICIE\"]>0) & (train_bo[\"CAMPAÑA\"]<22)]\n",
    "superficie_nonull_22 = train_bo[(train_bo[\"SUPERFICIE\"]>0) & (train_bo[\"CAMPAÑA\"]==22)]\n",
    "i_null = superficie_null.set_index(keys).index\n",
    "i_nonull = superficie_nonull.set_index(keys).index\n",
    "i_nonull_22 = superficie_nonull_22.set_index(keys).index\n",
    "superficie_null = superficie_null[i_null.isin(i_nonull_22)]\n",
    "llista = []\n",
    "for x,index in zip(superficie_null.values,superficie_null.index):\n",
    "    valor =  superficie_nonull_22.loc[(superficie_nonull_22.ID_FINCA == x[1]) & (superficie_nonull_22.VARIEDAD == x[5])\n",
    "                       & (superficie_nonull_22.MODO == x[6]) & (superficie_nonull_22.TIPO == x[7]),\"SUPERFICIE\"]\n",
    "    superficie_null.loc[(superficie_null.CAMPAÑA==x[0]) & (superficie_null.ID_FINCA == x[1]) & (superficie_null.VARIEDAD == x[5])\n",
    "                       & (superficie_null.MODO == x[6]) & (superficie_null.TIPO == x[7]),\"SUPERFICIE\"] = valor.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "es1raFMppIaO"
   },
   "outputs": [],
   "source": [
    "train_bo.loc[superficie_null.index,\"SUPERFICIE\"] = superficie_null[\"SUPERFICIE\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD-z8mdEk7ed"
   },
   "source": [
    "Llenamos con un KNN imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fFFtV7iok63P"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,2))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "def corregir_superficie_2(data,año):\n",
    "    data = data[data[\"CAMPAÑA\"] == año]\n",
    "    data = pd.get_dummies(data, columns = [\"ID_ESTACION\",\"VARIEDAD\"])\n",
    "    data[\"SUPERFICIE\"].replace(0, np.nan, inplace=True)\n",
    "    data.drop([\"CAMPAÑA\",\"ID_FINCA\",\"COLOR\",\"TIPO\",\"ID_ZONA\"],axis=1,inplace=True)\n",
    "    scaler.fit(data[\"PRODUCCION\"].to_numpy().reshape(-1, 1))\n",
    "    data[\"PRODUCCION\"] = scaler.transform(data[\"PRODUCCION\"].to_numpy().reshape(-1, 1))\n",
    "    scaler2.fit(data[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "    data[\"ALTITUD\"]= scaler2.transform(data[\"ALTITUD\"].to_numpy().reshape(-1,1))\n",
    "    imputer = KNNImputer(n_neighbors = 3)\n",
    "    data[\"SUPERFICIE\"] = imputer.fit_transform(data)[:,2]\n",
    "    train_bo.loc[train_bo.CAMPAÑA == año, 'SUPERFICIE'] = data[\"SUPERFICIE\"]\n",
    "\n",
    "train_bo_copia = train_bo.copy()\n",
    "#Evitamos imputar con los nuevos valores añadidos\n",
    "corregir_superficie_2(train_bo_copia.copy(),14)\n",
    "corregir_superficie_2(train_bo_copia.copy(),15)\n",
    "corregir_superficie_2(train_bo_copia.copy(),16)\n",
    "corregir_superficie_2(train_bo_copia.copy(),17)\n",
    "corregir_superficie_2(train_bo_copia.copy(),18)\n",
    "corregir_superficie_2(train_bo_copia.copy(),19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMTmO18v7Giy"
   },
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tj2_pn-G7Giy"
   },
   "source": [
    "La producción se puede explicar mayoritariamente por la superfície, y lo interesante es encontrar los demás factores que nos pueden ayudar a explicar la producción.\n",
    "Dado que los datos que podemos añadir son climatológicos, que en este caso estan representados de manera indirecta por las estaciones y la campaña, nos es de interés saber la variación de la producción por hectárea por campaña y estacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIMkYvUc7Giy"
   },
   "source": [
    "Observamos unos cuantos outliers en lo que a producción por hectárea se refiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "J6lLSWjv7Giz"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "train_varianza = train_bo.copy()\n",
    "train_varianza[\"PRODUCCION\"] = train_varianza[\"PRODUCCION\"]/train_bo[\"SUPERFICIE\"]\n",
    "train_varianza = train_varianza[train_varianza[\"CAMPAÑA\"]<22]\n",
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(train_varianza[\"PRODUCCION\"]))\n",
    "#indices = z[(z>1.9)].index\n",
    "\n",
    "indices = np.where(z>1.9)[0]\n",
    "outliers = train_bo.iloc[indices]\n",
    "train_varianza = train_varianza.drop(index=indices)\n",
    "train_bo = train_bo.drop(index=indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 383,  574,  615, 1321, 1718, 1772, 1976, 2201, 2241, 2648, 2825,\n",
       "       3141, 3317, 3326, 3873, 3925, 4345, 4947, 4993, 5406, 6063, 7090])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(z>1.9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rFsZVhmRpIaQ"
   },
   "outputs": [],
   "source": [
    "indices = train_varianza.index[train_varianza[\"PRODUCCION\"]<200]\n",
    "train_bo = train_bo.drop(index=indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOuYixsEpIaR"
   },
   "source": [
    "### Feature Engineering Estimación Producción por hectárea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9OR3YQnpIaR"
   },
   "source": [
    "#### Estimacion Campaña 22 con 20 y 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ns1QNZO2pIaR"
   },
   "outputs": [],
   "source": [
    "train_bo[\"ESTIMACION\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1CQZn7d4pIaR"
   },
   "outputs": [],
   "source": [
    "fincas_22 = train_bo[train_bo[\"CAMPAÑA\"]==22]\n",
    "fincas_21 = train_bo[train_bo[\"CAMPAÑA\"]==21]\n",
    "fincas_20 = train_bo[train_bo[\"CAMPAÑA\"]==20]\n",
    "\n",
    "keys = list(train_bo[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\",\"SUPERFICIE\"]].columns.values)\n",
    "\n",
    "i_22 = fincas_22.set_index(keys).index\n",
    "i_21 = fincas_21.set_index(keys).index\n",
    "i_20 = fincas_20.set_index(keys).index\n",
    "\n",
    "fincas_iguales = i_22[i_22.isin(i_21[i_21.isin(i_20)])]\n",
    "lista_indices = []\n",
    "\n",
    "for fincas in fincas_iguales:\n",
    "    finca_20 = fincas_20.loc[(fincas_20.ID_FINCA == fincas[0]) & (fincas_20.VARIEDAD == fincas[1]) & (fincas_20.MODO == fincas[2])\n",
    "                            &(fincas_20.TIPO==fincas[3]) & (fincas_20.SUPERFICIE == fincas[4])]\n",
    "    finca_21 = fincas_21.loc[(fincas_21.ID_FINCA == fincas[0]) & (fincas_21.VARIEDAD == fincas[1]) & (fincas_21.MODO == fincas[2])\n",
    "                            &(fincas_21.TIPO==fincas[3]) & (fincas_21.SUPERFICIE == fincas[4])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == fincas[0]) & (fincas_22.VARIEDAD == fincas[1]) & (fincas_22.MODO == fincas[2])\n",
    "                            &(fincas_22.TIPO==fincas[3]) & (fincas_22.SUPERFICIE == fincas[4])]\n",
    "    if((np.abs(finca_20[\"PRODUCCION\"].values-finca_21[\"PRODUCCION\"].values) <5000) | (np.abs(finca_20[\"PRODUCCION\"].values/fincas[4]-finca_21[\"PRODUCCION\"].values/fincas[4])<3500)):\n",
    "        estimacion = (finca_20[\"PRODUCCION\"].values/fincas[4]+finca_21[\"PRODUCCION\"].values/fincas[4])/2\n",
    "        train_bo.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_20.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pJSk75U0pIaR"
   },
   "outputs": [],
   "source": [
    "fincas_22= fincas_22.loc[fincas_22.ESTIMACION == 0]\n",
    "keys = list(train_bo[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\"]].columns.values)\n",
    "\n",
    "i_22 = fincas_22.set_index(keys).index\n",
    "i_21 = fincas_21.set_index(keys).index\n",
    "i_20 = fincas_20.set_index(keys).index\n",
    "\n",
    "fincas_iguales_1 = i_22[i_22.isin(i_21[i_21.isin(i_20)])]\n",
    "lista_indices = []\n",
    "\n",
    "for fincas in fincas_iguales_1:\n",
    "    finca_20 = fincas_20.loc[(fincas_20.ID_FINCA == fincas[0]) & (fincas_20.VARIEDAD == fincas[1]) & (fincas_20.MODO == fincas[2])\n",
    "                            &(fincas_20.TIPO==fincas[3])]\n",
    "    finca_21 = fincas_21.loc[(fincas_21.ID_FINCA == fincas[0]) & (fincas_21.VARIEDAD == fincas[1]) & (fincas_21.MODO == fincas[2])\n",
    "                            &(fincas_21.TIPO==fincas[3])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == fincas[0]) & (fincas_22.VARIEDAD == fincas[1]) & (fincas_22.MODO == fincas[2])\n",
    "                            &(fincas_22.TIPO==fincas[3])]\n",
    "    estimacion = (finca_20[\"PRODUCCION\"].values/finca_20[\"SUPERFICIE\"].values+finca_21[\"PRODUCCION\"].values/finca_21[\"SUPERFICIE\"].values)/2\n",
    "    if((np.abs(finca_20[\"PRODUCCION\"].values-finca_21[\"PRODUCCION\"].values) <4000) | (np.abs(finca_20[\"PRODUCCION\"].values/finca_20[\"SUPERFICIE\"].values-finca_21[\"PRODUCCION\"].values/finca_21[\"SUPERFICIE\"].values)<2000)):\n",
    "        train_bo.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_20.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EICirBKLpIaR"
   },
   "outputs": [],
   "source": [
    "fincas_22= fincas_22.loc[fincas_22.ESTIMACION == 0]\n",
    "fincas_antes = train_bo[train_bo[\"CAMPAÑA\"]<21]\n",
    "keys = list(train_bo[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\"]].columns.values)\n",
    "\n",
    "i_22 = fincas_22.set_index(keys).index\n",
    "i_21 = fincas_21.set_index(keys).index\n",
    "i_antes = fincas_antes.set_index(keys).index\n",
    "\n",
    "i_22 = i_22[~i_22.isin(i_antes)]\n",
    "fincas_iguales_2 = i_22[i_22.isin(i_21)]\n",
    "lista_indices = []\n",
    "for fincas in fincas_iguales_2:\n",
    "    finca_21 = fincas_21.loc[(fincas_21.ID_FINCA == fincas[0]) & (fincas_21.VARIEDAD == fincas[1]) & (fincas_21.MODO == fincas[2])\n",
    "                            &(fincas_21.TIPO==fincas[3])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == fincas[0]) & (fincas_22.VARIEDAD == fincas[1]) & (fincas_22.MODO == fincas[2])\n",
    "                            &(fincas_22.TIPO==fincas[3])]\n",
    "\n",
    "    estimacion = finca_21[\"PRODUCCION\"].values/finca_21[\"SUPERFICIE\"].values\n",
    "    \n",
    "    train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "    train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKq8CGIKpIaS"
   },
   "source": [
    "#### Estimacion Campaña 22 con todas las fincas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LS0KseqKpIaS"
   },
   "outputs": [],
   "source": [
    "fincas_22= fincas_22.loc[fincas_22.ESTIMACION == 0]\n",
    "fincas_todas = train_bo[train_bo[\"CAMPAÑA\"]<22]\n",
    "keys = list(train_bo[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\"]].columns.values)\n",
    "\n",
    "i_22 = fincas_22.set_index(keys).index\n",
    "i_todas = fincas_todas.set_index(keys).index\n",
    "\n",
    "fincas_iguales_todas = i_22[i_22.isin(i_todas)]\n",
    "\n",
    "for finca in fincas_iguales_todas:\n",
    "    fincas = fincas_todas.loc[(fincas_todas.ID_FINCA == finca[0]) & (fincas_todas.VARIEDAD == finca[1]) & (fincas_todas.MODO == finca[2])\n",
    "                            &(fincas_todas.TIPO==finca[3])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == finca[0]) & (fincas_22.VARIEDAD == finca[1]) & (fincas_22.MODO == finca[2])\n",
    "                            &(fincas_22.TIPO==finca[3])]\n",
    "\n",
    "    estimacion = np.mean(fincas[\"PRODUCCION\"]/fincas[\"SUPERFICIE\"])\n",
    "    \n",
    "    train_bo.loc[fincas.index,\"ESTIMACION\"] = estimacion\n",
    "    train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_todas.loc[fincas.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OecuwooYpIaS"
   },
   "outputs": [],
   "source": [
    "fincas_22= fincas_22.loc[fincas_22.ESTIMACION == 0]\n",
    "keys = list(train_bo[[\"ID_FINCA\",\"VARIEDAD\",\"TIPO\"]].columns.values)\n",
    "\n",
    "i_22 = fincas_22.set_index(keys).index\n",
    "i_21 = fincas_21.set_index(keys).index\n",
    "i_20 = fincas_20.set_index(keys).index\n",
    "\n",
    "fincas_iguales_3 = i_22[i_22.isin(i_21)]\n",
    "fincas_iguales_4 = i_22[i_22.isin(i_20)]\n",
    "\n",
    "lista_indices = []\n",
    "#Tendremos que mirar que el modo para todas sean diferentes, porque sino se tratará de un caso que antes hemos descartado de llenar\n",
    "conjunto_20_21 = fincas_21.append(fincas_20)\n",
    "medias_modo0 = np.mean(conjunto_20_21.loc[conjunto_20_21.MODO==0][\"PRODUCCION\"]/conjunto_20_21.loc[conjunto_20_21.MODO==0][\"SUPERFICIE\"])\n",
    "medias_modo1 = np.mean(conjunto_20_21.loc[conjunto_20_21.MODO==1][\"PRODUCCION\"]/conjunto_20_21.loc[conjunto_20_21.MODO==1][\"SUPERFICIE\"])\n",
    "# se espera una producción 50% mayor si es con modo 1 medias_modo1/medias_modo0\n",
    "\n",
    "#Primero llenaremos aquellas que estan solo en la campaña 20 o 21, y luego las que estan en ambas (solo hay un caso en la campaña 21)\n",
    "fincas_modo_21 = fincas_iguales_3[~fincas_iguales_3.isin(fincas_iguales_4)]\n",
    "for fincas in fincas_modo_21:\n",
    "    finca_21 = fincas_21.loc[(fincas_21.ID_FINCA == fincas[0]) & (fincas_21.VARIEDAD == fincas[1]) \n",
    "                            &(fincas_21.TIPO==fincas[2])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == fincas[0]) & (fincas_22.VARIEDAD == fincas[1]) \n",
    "                            &(fincas_22.TIPO==fincas[2])]\n",
    "    if (finca_21[\"MODO\"].values[0] != finca_22[\"MODO\"].values):\n",
    "        estimacion = finca_21[\"PRODUCCION\"].values[0]/finca_21[\"SUPERFICIE\"].values[0]\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion*finca_21[\"MODO\"].values[0]/1.5 + estimacion*finca_22[\"MODO\"].values*1.5 \n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "    elif (len(finca_21[\"MODO\"].values)>1):\n",
    "        estimacion = finca_21[\"PRODUCCION\"].values[1]/finca_21[\"SUPERFICIE\"].values[1]\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5\n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "    \n",
    "#Ahora aquellas que aparecen en las campañas 20,21 y 22    \n",
    "fincas_iguales = i_22[i_22.isin(i_21[i_21.isin(i_20)])]\n",
    "for fincas in fincas_iguales:\n",
    "    finca_20 = fincas_20.loc[(fincas_20.ID_FINCA == fincas[0]) & (fincas_20.VARIEDAD == fincas[1]) \n",
    "                            &(fincas_20.TIPO==fincas[2])]\n",
    "    finca_21 = fincas_21.loc[(fincas_21.ID_FINCA == fincas[0]) & (fincas_21.VARIEDAD == fincas[1]) \n",
    "                            &(fincas_21.TIPO==fincas[2])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.ID_FINCA == fincas[0]) & (fincas_22.VARIEDAD == fincas[1]) \n",
    "                            &(fincas_22.TIPO==fincas[2])]\n",
    "    \n",
    "    finca_20 = finca_20.loc[finca_20.MODO.values != finca_22.MODO.values]\n",
    "    finca_21 = finca_21.loc[finca_21.MODO.values != finca_22.MODO.values]\n",
    "\n",
    "    modo_22 = finca_22[\"MODO\"].values\n",
    "    #comprovamos si hay algun modo diferente\n",
    "    if (len(finca_20)==1 and len(finca_21)==1):\n",
    "        estimacion = (finca_20[\"PRODUCCION\"].values/finca_20[\"SUPERFICIE\"].values+finca_21[\"PRODUCCION\"].values/finca_21[\"SUPERFICIE\"].values)/2\n",
    "        train_bo.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n",
    "        fincas_20.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n",
    "    elif(len(finca_20)==1):\n",
    "        estimacion = finca_20[\"PRODUCCION\"].values/finca_20[\"SUPERFICIE\"].values\n",
    "        train_bo.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n",
    "        fincas_20.loc[finca_20.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n",
    "    elif(len(finca_21)==1):\n",
    "        estimacion = finca_21[\"PRODUCCION\"].values/finca_21[\"SUPERFICIE\"].values\n",
    "        train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n",
    "        fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "        fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion/1.5 *(1-modo_22) + estimacion*1.5*modo_22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNYBRMTwpIaT"
   },
   "source": [
    "#### Estimacion Campaña 22 con Variedad y Modo de Cultivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vtrKfsK2pIaT"
   },
   "outputs": [],
   "source": [
    "fincas_22= fincas_22.loc[fincas_22.ESTIMACION == 0]\n",
    "keys = list(train_bo[[\"VARIEDAD\",\"MODO\"]].columns.values)\n",
    "i_22 = fincas_22.set_index(keys).index.drop_duplicates()\n",
    "for comb in i_22:\n",
    "    fincas = conjunto_20_21.loc[(conjunto_20_21.VARIEDAD == comb[0]) & (conjunto_20_21.MODO == comb[1])]\n",
    "    finca_22 = fincas_22.loc[(fincas_22.VARIEDAD == comb[0]) & (fincas_22.MODO == comb[1])]\n",
    "\n",
    "    estimacion = np.mean(fincas[\"PRODUCCION\"]/fincas[\"SUPERFICIE\"])\n",
    "    train_bo.loc[finca_22.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_22.loc[finca_22.index,\"ESTIMACION\"] = estimacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-B2ztNPpIaT"
   },
   "source": [
    "#### Estimación todas las campañas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OMmchct4pIaU"
   },
   "outputs": [],
   "source": [
    "train_finca = train_bo[train_bo[\"CAMPAÑA\"]<22]\n",
    "keys = list(train_finca[[\"VARIEDAD\",\"ID_FINCA\",\"TIPO\",\"MODO\"]].columns.values)\n",
    "\n",
    "fincas = train_finca.set_index(keys).index.drop_duplicates()\n",
    "\n",
    "for com in fincas:\n",
    "    estimacion = np.mean(train_finca.loc[(train_finca[\"VARIEDAD\"]==com[0]) & (train_finca[\"ID_FINCA\"]==com[1]) & (train_finca[\"TIPO\"]==com[2]),\"PRODUCCION\"]/train_finca.loc[(train_finca[\"VARIEDAD\"]==com[0]) & (train_finca[\"ID_FINCA\"]==com[1]) & (train_finca[\"TIPO\"]==com[2]),\"SUPERFICIE\"])\n",
    "    if (len(train_finca.loc[(train_finca[\"VARIEDAD\"]==com[0]) & (train_finca[\"ID_FINCA\"]==com[1]) & (train_finca[\"TIPO\"]==com[2])])>1):\n",
    "        train_finca.loc[(train_finca[\"VARIEDAD\"]==com[0]) & (train_finca[\"ID_FINCA\"]==com[1]) & (train_finca[\"TIPO\"]==com[2]) & (train_finca[\"ESTIMACION\"]==0),\"ESTIMACION\"] = estimacion\n",
    "        train_bo.loc[(train_bo[\"VARIEDAD\"]==com[0]) & (train_bo[\"ID_FINCA\"]==com[1]) & (train_bo[\"TIPO\"]==com[2]) & (train_bo[\"ESTIMACION\"]==0),\"ESTIMACION\"] = estimacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JvwL37l1pIaU"
   },
   "outputs": [],
   "source": [
    "fincas_21= train_finca.loc[(train_finca.ESTIMACION == 0 ) &  (train_finca.CAMPAÑA ==21)]\n",
    "keys = list(train_bo[[\"VARIEDAD\",\"MODO\"]].columns.values)\n",
    "i_21 = fincas_21.set_index(keys).index.drop_duplicates()\n",
    "for comb in i_22:\n",
    "    fincas = train_finca.loc[(train_finca.VARIEDAD == comb[0]) & (train_finca.MODO == comb[1])]\n",
    "    finca_21 = fincas_21.loc[(fincas_21.VARIEDAD == comb[0]) & (fincas_21.MODO == comb[1])]\n",
    "    estimacion = np.mean(fincas[\"PRODUCCION\"]/fincas[\"SUPERFICIE\"])\n",
    "    train_bo.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "    fincas_21.loc[finca_21.index,\"ESTIMACION\"] = estimacion\n",
    "train_bo = train_bo.loc[train_bo.ESTIMACION !=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpllU4IrpIaU"
   },
   "source": [
    "#### Factor Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "boMAXxRfpIaV"
   },
   "outputs": [],
   "source": [
    "train_bo[\"ESTIMACION_PRODUCCION\"] = train_bo[\"ESTIMACION\"]*train_bo[\"SUPERFICIE\"]\n",
    "train_bo[\"FACTOR_PRODUCCION\"] = train_bo[\"PRODUCCION\"]/train_bo[\"ESTIMACION_PRODUCCION\"]\n",
    "cambio_signo = -1/train_bo[train_bo[\"FACTOR_PRODUCCION\"]<1][\"FACTOR_PRODUCCION\"]\n",
    "train_bo.loc[train_bo.FACTOR_PRODUCCION<1,\"FACTOR_PRODUCCION\"] = cambio_signo+1\n",
    "train_bo.loc[train_bo.FACTOR_PRODUCCION>0,\"FACTOR_PRODUCCION\"] = train_bo.loc[train_bo.FACTOR_PRODUCCION>0,\"FACTOR_PRODUCCION\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "jSXuDFJTpIaV"
   },
   "outputs": [],
   "source": [
    "index_outliers = train_bo.index[np.abs(train_bo[\"FACTOR_PRODUCCION\"])>5]\n",
    "train_bo = train_bo[~train_bo.index.isin(index_outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tJX5-rlpIaV"
   },
   "source": [
    "#### Quitamos campañas 14 y 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gOU0G0VGpIaV"
   },
   "outputs": [],
   "source": [
    "train_bo= train_bo.loc[(train_bo.CAMPAÑA != 14) & (train_bo.CAMPAÑA !=15)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXjJR41Ax4gD"
   },
   "source": [
    "## ETO Y METEO DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wkgb8FB4pIaW"
   },
   "source": [
    "### ETO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCnmLRWvpIaW"
   },
   "source": [
    "#### Formato Fecha y eliminación de datos innecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Oqmq7OShOEqr"
   },
   "outputs": [],
   "source": [
    "ETO_dataset['date'] = pd.to_datetime(ETO_dataset['date'], format=\"%Y%m%d\")\n",
    "for i,j in enumerate(ETO_dataset.keys()):\n",
    "    if j == \"date\" :\n",
    "        continue\n",
    "    elif j == 'ID_ESTACION':\n",
    "        continue\n",
    "    elif \"Day\" not in j:\n",
    "        ETO_dataset.drop(j, axis=1, inplace=True)\n",
    "    elif \"Daytime\" in j:\n",
    "        ETO_dataset.drop(j, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FRRq6Birox3L"
   },
   "outputs": [],
   "source": [
    "ETO_dataset=ETO_dataset.drop('FeelsLikeLocalDayAvg', axis=1)\n",
    "ETO_dataset=ETO_dataset.drop('FeelsLikeLocalDayMax', axis=1)\n",
    "ETO_dataset=ETO_dataset.drop('FeelsLikeLocalDayMin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gg78kQ2dTM2t"
   },
   "outputs": [],
   "source": [
    "ETO_dataset['Week'] = ETO_dataset['date'].dt.week\n",
    "ETO_dataset['Month'] = ETO_dataset['date'].dt.month\n",
    "ETO_dataset['Year'] = ETO_dataset['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi5naWJEpIaX"
   },
   "source": [
    "### Imputation de los valores NaN con modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_TMjbz4PTM2u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ETO_dataset = ETO_dataset.drop([\"EvapotranspirationLocalDayMax\",\"EvapotranspirationLocalDayMin\",\"EvapotranspirationLocalDayMin\",\"EvapotranspirationLocalDayMax\",\n",
    "                \"GlobalHorizontalIrradianceLocalDayMax\",\"GlobalHorizontalIrradianceLocalDayMin\",\"MSLPLocalDayMax\",\"MSLPLocalDayMin\",\"GustLocalDayMax\",\"GustLocalDayMin\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8Jx9obZpIaX"
   },
   "source": [
    "#### Evatranspiración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "DRY5x3yppIaX"
   },
   "outputs": [],
   "source": [
    "Evatransporation = ETO_dataset.drop([\"MSLPLocalDayAvg\",\"GustLocalDayAvg\",\"GlobalHorizontalIrradianceLocalDayAvg\",\"date\",\"ID_ESTACION\"],axis=1)\n",
    "X = Evatransporation[~Evatransporation.isnull().any(axis=1)]\n",
    "target_y = X[\"EvapotranspirationLocalDayAvg\"]\n",
    "Pred_X = Evatransporation[Evatransporation.isnull().any(axis=1)].drop(\"EvapotranspirationLocalDayAvg\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dpEYnjzfpIaX"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score,confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop([\"EvapotranspirationLocalDayAvg\"],axis=1), (target_y*10).astype(int)\n",
    ", test_size=0.3, random_state=99)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)\n",
    "regr = RandomForestClassifier(n_estimators = 1000,max_depth=25, random_state=0,n_jobs=-1)\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "prediccio = regr.predict(X_test)\n",
    "\n",
    "X_pred = model.transform(Pred_X)\n",
    "EV_pred =regr.predict(X_pred)\n",
    "Pred_X[\"EvapotranspirationLocalDayAvg\"] = EV_pred/10\n",
    "ETO_dataset.loc[ETO_dataset.index.isin(Pred_X[\"EvapotranspirationLocalDayAvg\"].index),\"EvapotranspirationLocalDayAvg\"] = Pred_X[\"EvapotranspirationLocalDayAvg\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SfInaqhpIaY"
   },
   "source": [
    "#### Presion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_8yAWAWipIaY"
   },
   "outputs": [],
   "source": [
    "Presion = ETO_dataset.drop([\"GustLocalDayAvg\",\"GlobalHorizontalIrradianceLocalDayAvg\",\"date\",\"ID_ESTACION\",\"Week\",\"Year\"],axis=1)\n",
    "X = Presion[~Presion.isnull().any(axis=1)]\n",
    "target_y = X[\"MSLPLocalDayAvg\"]\n",
    "Pred_X = Presion[Presion.isnull().any(axis=1)].drop(\"MSLPLocalDayAvg\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "wJHpP0zhpIaY"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(\"MSLPLocalDayAvg\",axis=1), target_y\n",
    ", test_size=0.3, random_state=99,shuffle=True)\n",
    "lasso = Lasso(alpha=0.3,fit_intercept=False).fit(X_train,y_train)\n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)\n",
    "regr = RandomForestRegressor(n_estimators = 200,max_depth=25, random_state=0,n_jobs=-1)\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "prediccio = regr.predict(X_test)\n",
    "X_pred = model.transform(Pred_X)\n",
    "Pres_pred =regr.predict(X_pred)\n",
    "Pred_X[\"MSLPLocalDayAvg\"] = Pres_pred\n",
    "ETO_dataset.loc[ETO_dataset.index.isin(Pred_X[\"MSLPLocalDayAvg\"].index),\"MSLPLocalDayAvg\"] = Pred_X[\"MSLPLocalDayAvg\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYFdIqEUTM2z"
   },
   "source": [
    "#### Radiacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Wpuot8_rTM2z"
   },
   "outputs": [],
   "source": [
    "Radiacion = ETO_dataset.drop([\"GustLocalDayAvg\",\"date\",\"ID_ESTACION\",\"Year\"],axis=1)\n",
    "X = Radiacion[~Radiacion.isnull().any(axis=1)]\n",
    "target_y = X[\"GlobalHorizontalIrradianceLocalDayAvg\"]\n",
    "Pred_X = Radiacion[Radiacion.isnull().any(axis=1)].drop(\"GlobalHorizontalIrradianceLocalDayAvg\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "2WHmJ-WfTM2z"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(\"GlobalHorizontalIrradianceLocalDayAvg\",axis=1), target_y\n",
    "                                                    , test_size=0.3, random_state=99,shuffle=True)\n",
    "lasso = Lasso(alpha=0.3,fit_intercept=False).fit(X_train,y_train)\n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)\n",
    "regr = RandomForestRegressor(n_estimators = 200,max_depth=30, random_state=0,n_jobs=-1)\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "prediccio = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "nK6HG5TJTM20"
   },
   "outputs": [],
   "source": [
    "X_pred = model.transform(Pred_X)\n",
    "Rad_pred =regr.predict(X_pred)\n",
    "Pred_X[\"GlobalHorizontalIrradianceLocalDayAvg\"] = Rad_pred\n",
    "ETO_dataset.loc[ETO_dataset.index.isin(Pred_X[\"GlobalHorizontalIrradianceLocalDayAvg\"].index),\"GlobalHorizontalIrradianceLocalDayAvg\"] = Pred_X[\"GlobalHorizontalIrradianceLocalDayAvg\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQpH8kQBpIaZ"
   },
   "source": [
    "Quitamos la lluvia mínima diaria y la nievie mínima diaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "n079t7iMTM22"
   },
   "outputs": [],
   "source": [
    "ETO_dataset.drop([\"PrecipAmountLocalDayMin\",\"SnowAmountLocalDayMin\"], axis=1, inplace=True)\n",
    "#Ni mínimo de lluvia diaria ni de nieve aporta nada, ya que sera 0 en la mayoría de casos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0rAcmemTM22"
   },
   "source": [
    "### METEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vzo1mFaLpIaa"
   },
   "source": [
    "#### Formato Fecha y eliminación de datos innecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "YbIQBj6eTM23"
   },
   "outputs": [],
   "source": [
    "def separate_by_space(string: str, index: int):\n",
    "    word_list = string.split() #converts string into a list of strings\n",
    "    return word_list[index]\n",
    "\n",
    "METEO_dataset['validTimeUtc'] = METEO_dataset['validTimeUtc'].astype('str')\n",
    "\n",
    "date = pd.DataFrame(METEO_dataset['validTimeUtc'].apply(lambda x: separate_by_space(x, 0)))\n",
    "METEO_dataset.insert(loc=0, column='date', value=date['validTimeUtc'])\n",
    "\n",
    "hour = pd.DataFrame(METEO_dataset['validTimeUtc'].apply(lambda x: separate_by_space(x, 1)))\n",
    "METEO_dataset.insert(loc=1, column='Hour', value=hour['validTimeUtc'])\n",
    "\n",
    "#METEO_dataset.drop('validTimeHour', axis=1, inplace=True)\n",
    "\n",
    "METEO_dataset['date'] = METEO_dataset['date'].str.replace('-', '')\n",
    "METEO_dataset['date'] = pd.to_datetime(METEO_dataset['date'], format=\"%Y%m%d\")\n",
    "METEO_dataset.drop('validTimeUtc', axis=1, inplace=True) # Ya no nos hace falta porque tenemos Date y Hour\n",
    "ETO_dataset['date'] = pd.to_datetime(ETO_dataset['date'], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rd2xHfuWTM25"
   },
   "outputs": [],
   "source": [
    "METEO_dataset['precip1Hour'].fillna(method='ffill',inplace=True)\n",
    "METEO_dataset['snow1Hour'].fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "QwTvOC7WTM25"
   },
   "outputs": [],
   "source": [
    "# Volume of rain\n",
    "suma_prec = METEO_dataset.groupby(['date','ID_ESTACION'])['precip1Hour'].agg(np.sum).reset_index().rename(columns={'precip1Hour':'precipDay'})\n",
    "ETO_dataset = ETO_dataset.merge(suma_prec,how=\"left\", on=[\"date\",\"ID_ESTACION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7RAvzJmpTM26",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ETO_dias = ETO_dataset.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVialJ5SpIab"
   },
   "source": [
    "### Series Temporales Para Llenar los meses de julio a octubre del 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Y0xIl1GPpIab"
   },
   "outputs": [],
   "source": [
    "ETO_series = ETO_dias[[\"date\",\"ID_ESTACION\",\"TemperatureLocalDayAvg\",\n",
    "                           \"GlobalHorizontalIrradianceLocalDayAvg\",\"WindSpeedLocalDayMax\",\"precipDay\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "MfalszQ5pIab"
   },
   "outputs": [],
   "source": [
    "Series_Temporales = []\n",
    "\n",
    "for id_estacion in np.unique(ETO_series[\"ID_ESTACION\"]):\n",
    "    Series_Temporales.append(ETO_series[ETO_series[\"ID_ESTACION\"]==id_estacion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "W7HdMkk-pIac"
   },
   "outputs": [],
   "source": [
    "for i,serie in enumerate(Series_Temporales):\n",
    "    serie = serie.append(pd.DataFrame({'date': pd.date_range(start=\"2022-06-30\", periods=130, freq='D', closed='right')}))\n",
    "    Series_Temporales[i] = serie.reset_index().drop(['index','ID_ESTACION'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "6m9LJsGQpIac",
    "outputId": "3c7d206f-874b-4d68-dbc8-ae548863a14d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:22:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:22:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:22:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:38 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:23:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:23:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:23:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "for i,serie in enumerate(Series_Temporales):\n",
    "    for col in serie.columns:\n",
    "        if col == \"date\":\n",
    "            pass\n",
    "        else:\n",
    "            data = serie[serie['date']<\"2022-07-01\"][['date',col]].rename(columns={'date':'ds',col:'y'})\n",
    "            m=Prophet()    \n",
    "            m.fit(data)\n",
    "            future = m.make_future_dataframe(periods=129)\n",
    "            forecast = m.predict(future)[['ds', 'yhat']]\n",
    "            forecast = forecast[forecast[\"ds\"]>\"2022-06-30\"]\n",
    "            Series_Temporales[i].loc[forecast.index,col] = forecast['yhat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "RYml5ZWjpIac"
   },
   "outputs": [],
   "source": [
    "Series_Temporales[0]['ID_ESTACION'] = 0\n",
    "ETO_series_temporales = Series_Temporales[0]\n",
    "for i,serie in enumerate(Series_Temporales[1:]):\n",
    "    serie['ID_ESTACION']= i+1\n",
    "    ETO_series_temporales= ETO_series_temporales.append(serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAlvWwCdTZyg"
   },
   "source": [
    "## Predicción final con datos meteorologicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "NMuekC1Pau8I"
   },
   "outputs": [],
   "source": [
    "ETO_series_temporales[\"Year\"] = ETO_series_temporales['date'].dt.year\n",
    "ETO_series_temporales['Month'] = ETO_series_temporales['date'].dt.month\n",
    "ETO_series_temporales['Week'] = ETO_series_temporales['date'].dt.week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVko4iDmpIad"
   },
   "source": [
    "Dataset Lluvia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "mEsBtDiSaW9N"
   },
   "outputs": [],
   "source": [
    "ETO_Lluvia = ETO_series_temporales[[\"precipDay\",\"Year\",\"Month\",\"ID_ESTACION\"]]\n",
    "mask1 = ETO_Lluvia[\"Month\"]>10\n",
    "ETO_Lluvia.loc[mask1, 'Year'] = ETO_Lluvia.loc[mask1]['Year']+1\n",
    "ETO_Lluvia = ETO_Lluvia.groupby([\"ID_ESTACION\",\"Year\",\"Month\"]).agg(np.sum).reset_index()\n",
    "ETO_Lluvia = ETO_Lluvia[(ETO_Lluvia[\"Year\"]>2015) & (ETO_Lluvia[\"Year\"]<2023)]\n",
    "ETO_Lluvia = ETO_Lluvia.pivot_table(\"precipDay\", ['Year', 'ID_ESTACION'], 'Month')\n",
    "ETO_Lluvia.columns = [\"Month_\"+str(col) for col in ETO_Lluvia.columns.values]\n",
    "ETO_Lluvia.reset_index(inplace=True)\n",
    "ETO_Lluvia[\"Year\"]=ETO_Lluvia[\"Year\"]-2000\n",
    "ETO_Lluvia.rename(columns={\"Year\":\"CAMPAÑA\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nGL05hhvpIad"
   },
   "outputs": [],
   "source": [
    "ETO_Lluvia[\"Precipitacion_Brotacion\"] = ETO_Lluvia[\"Month_3\"] +  ETO_Lluvia[\"Month_4\"] + ETO_Lluvia[\"Month_5\"]\n",
    "ETO_Lluvia[\"Precipitacion_Crecimiento\"] = ETO_Lluvia[\"Month_6\"] +  ETO_Lluvia[\"Month_7\"] + ETO_Lluvia[\"Month_8\"]\n",
    "ETO_Lluvia[\"Precipitacion_Maduracion\"] = ETO_Lluvia[\"Month_9\"] +  ETO_Lluvia[\"Month_10\"]\n",
    "ETO_Lluvia[\"Precipitacion_Reserva\"] = ETO_Lluvia[\"Month_11\"] +  ETO_Lluvia[\"Month_12\"] + ETO_Lluvia[\"Month_1\"] +  ETO_Lluvia[\"Month_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "2xe9ZaURpIae"
   },
   "outputs": [],
   "source": [
    "ETO_Lluvia=ETO_Lluvia[[\"CAMPAÑA\",\"ID_ESTACION\",\"Precipitacion_Reserva\",\"Precipitacion_Maduracion\",\"Precipitacion_Crecimiento\",\"Precipitacion_Brotacion\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D41UkskGpIaf"
   },
   "source": [
    "Dataset Temperatura, Radiación y Viento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ElbD8ZRWpIaf"
   },
   "outputs": [],
   "source": [
    "ETO_series_temporales = ETO_series_temporales[(ETO_series_temporales[\"Month\"]>2) & (ETO_series_temporales[\"Month\"]<11)]\n",
    "ETO_Clima = ETO_series_temporales.groupby([\"ID_ESTACION\",\"Year\",\"Month\"]).agg(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "o2RsuLq2pIaf"
   },
   "outputs": [],
   "source": [
    "ETO_Clima = ETO_Clima[(ETO_Clima[\"Year\"]>2015) & (ETO_Clima[\"Year\"]<2023)]\n",
    "\n",
    "\n",
    "def modify_data(feature):\n",
    "    data = ETO_Clima.pivot_table(feature, ['Year', 'ID_ESTACION'], 'Month')\n",
    "    data.columns = [\"Month_\"+str(col) for col in data.columns.values]\n",
    "    data.reset_index(inplace=True)\n",
    "    data[\"Year\"]=data[\"Year\"]-2000\n",
    "\n",
    "    data.rename(columns={\"Year\":\"CAMPAÑA\"},inplace=True)\n",
    "    return data\n",
    "\n",
    "ETO_Temperatura = modify_data(\"TemperatureLocalDayAvg\")\n",
    "ETO_Viento = modify_data(\"WindSpeedLocalDayMax\")\n",
    "ETO_Radiacion = modify_data(\"GlobalHorizontalIrradianceLocalDayAvg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "YMKIUH7bpIaf"
   },
   "outputs": [],
   "source": [
    "ETO_Temperatura[\"Temperatura_Brotacion\"] = (ETO_Temperatura[\"Month_3\"] +  ETO_Temperatura[\"Month_4\"] + ETO_Temperatura[\"Month_5\"])/3\n",
    "ETO_Temperatura[\"Temperatura_Crecimiento\"] = (ETO_Temperatura[\"Month_6\"] +  ETO_Temperatura[\"Month_7\"] + ETO_Temperatura[\"Month_8\"] )/3\n",
    "ETO_Temperatura[\"Temperatura_Maduracion\"] = (ETO_Temperatura[\"Month_9\"] +  ETO_Temperatura[\"Month_10\"])/2\n",
    "\n",
    "ETO_Temperatura=ETO_Temperatura[[\"CAMPAÑA\",\"ID_ESTACION\",\"Temperatura_Brotacion\",\"Temperatura_Crecimiento\",\"Temperatura_Maduracion\"]]\n",
    "\n",
    "ETO_Viento[\"Viento_Brotacion\"] = (ETO_Viento[\"Month_3\"] +  ETO_Viento[\"Month_4\"] + ETO_Viento[\"Month_5\"])/3\n",
    "ETO_Viento[\"Viento_Crecimiento\"] = ( ETO_Viento[\"Month_6\"] +  ETO_Viento[\"Month_7\"] + ETO_Viento[\"Month_8\"])/3\n",
    "ETO_Viento[\"Viento_Maduracion\"] = ( ETO_Viento[\"Month_9\"] +  ETO_Viento[\"Month_10\"])/2\n",
    "\n",
    "ETO_Viento=ETO_Viento[[\"CAMPAÑA\",\"ID_ESTACION\",\"Viento_Brotacion\",\"Viento_Crecimiento\",\"Viento_Maduracion\"]]\n",
    "\n",
    "ETO_Radiacion[\"Radiacion_Brotacion\"] = (ETO_Radiacion[\"Month_3\"] +  ETO_Radiacion[\"Month_4\"] + ETO_Radiacion[\"Month_5\"])/3\n",
    "ETO_Radiacion[\"Radiacion_Crecimiento\"] = (ETO_Radiacion[\"Month_6\"] +  ETO_Radiacion[\"Month_7\"] + ETO_Radiacion[\"Month_8\"])/3\n",
    "ETO_Radiacion[\"Radiacion_Maduracion\"] = (ETO_Radiacion[\"Month_9\"] +  ETO_Radiacion[\"Month_10\"])/2\n",
    "\n",
    "ETO_Radiacion=ETO_Radiacion[[\"CAMPAÑA\",\"ID_ESTACION\",\"Radiacion_Brotacion\",\"Radiacion_Crecimiento\",\"Radiacion_Maduracion\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URNQ3_kQpIag"
   },
   "source": [
    "### Modelos Finales/ Ensemble de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT9BG9d3pIag"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "p48iIOwwpIag"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_bo[(train_bo[\"CAMPAÑA\"]>15)]\n",
    "train_dataset = train_dataset.merge(ETO_Lluvia,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "train_dataset= train_dataset.merge(ETO_Viento,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "train_dataset= train_dataset.merge(ETO_Radiacion,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "\n",
    "train_set_data = train_dataset[(train_dataset[\"CAMPAÑA\"]<22)]\n",
    "pred_set_data = train_dataset[train_dataset[\"CAMPAÑA\"]==22]\n",
    "\n",
    "train_set_data.drop([\"CAMPAÑA\",\"ID_FINCA\",\"ID_ESTACION\",\"ID_ZONA\"],axis=1,inplace=True)\n",
    "\n",
    "train_set_data = train_set_data[np.abs(train_set_data[\"FACTOR_PRODUCCION\"])<1.6]\n",
    "\n",
    "pred_set = pred_set_data.drop([\"PRODUCCION\",\"FACTOR_PRODUCCION\",\"CAMPAÑA\",\"ID_FINCA\",\"ID_ESTACION\",\"ID_ZONA\"],axis=1)\n",
    "\n",
    "X_train = train_set_data.drop([\"PRODUCCION\",\"FACTOR_PRODUCCION\"],axis=1)\n",
    "y_train = train_set_data[\"PRODUCCION\"]\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators = 300,max_depth=25, min_samples_split =6, random_state=0, n_jobs=-1)\n",
    "regr.fit(X_train,y_train)\n",
    "prediccion_rf = regr.predict(pred_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yIBhmxOpIah"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "n2xOeUGjpIah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/marc/anaconda3/lib/python3.9/site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in /home/marc/anaconda3/lib/python3.9/site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in /home/marc/anaconda3/lib/python3.9/site-packages (from xgboost) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "train_dataset = train_bo[(train_bo[\"CAMPAÑA\"]>15)]\n",
    "train_dataset = train_dataset.merge(ETO_Lluvia,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "train_dataset= train_dataset.merge(ETO_Temperatura,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "train_dataset= train_dataset.merge(ETO_Viento,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "train_dataset= train_dataset.merge(ETO_Radiacion,how=\"left\",on=[\"CAMPAÑA\",\"ID_ESTACION\"])\n",
    "\n",
    "train_set_data = train_dataset[(train_dataset[\"CAMPAÑA\"]<22)]\n",
    "pred_set_data = train_dataset[train_dataset[\"CAMPAÑA\"]==22]\n",
    "\n",
    "train_set_data.drop([\"CAMPAÑA\",\"ID_FINCA\",\"ID_ESTACION\",\"ID_ZONA\"],axis=1,inplace=True)\n",
    "\n",
    "train_set_data = train_set_data[np.abs(train_set_data[\"FACTOR_PRODUCCION\"])<1.6]\n",
    "\n",
    "pred_set = pred_set_data.drop([\"PRODUCCION\",\"FACTOR_PRODUCCION\",\"CAMPAÑA\",\"ID_FINCA\",\"ID_ESTACION\",\"ID_ZONA\"],axis=1)\n",
    "\n",
    "X_train = train_set_data.drop([\"PRODUCCION\",\"FACTOR_PRODUCCION\"],axis=1)\n",
    "y_train = train_set_data[\"PRODUCCION\"]\n",
    "\n",
    "\n",
    "regr = XGBRegressor(n_estimators = 90,reg_lambda=0.8,min_child_weight=5,subsample = 0.7,colsample_bytree=0.7,booster='gbtree',eta=0.1,max_depth=3, tree_method=\"exact\",objective = \"reg:squarederror\",\n",
    "                         eval_metric = \"rmse\").fit(X_train,y_train)\n",
    "    \n",
    "prediccion_xgb = regr.predict(pred_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "xpEBvqYfpIah"
   },
   "outputs": [],
   "source": [
    "prediccion_estimacion = pred_set[\"ESTIMACION_PRODUCCION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "6FMRVNwCpIah"
   },
   "outputs": [],
   "source": [
    "prediccion_final = 0.18 * prediccion_estimacion + 0.14 * prediccion_xgb + 0.68 * prediccion_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKwlUguspIah"
   },
   "source": [
    "### Entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "hbW2Je8-pIah"
   },
   "outputs": [],
   "source": [
    "pred_set_data[\"PRODUCCION\"] = prediccion_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "vIeyFBRSpIah"
   },
   "outputs": [],
   "source": [
    "entrega = pred_set_data[[\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\",\"COLOR\",\"SUPERFICIE\",\"PRODUCCION\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "t4P_ZtI4pIah"
   },
   "outputs": [],
   "source": [
    "entrega = entrega.sort_values([\"ID_FINCA\",\"VARIEDAD\",\"MODO\",\"TIPO\",\"COLOR\",\"SUPERFICIE\",\"PRODUCCION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "YRADVXIgpIah"
   },
   "outputs": [],
   "source": [
    "entrega[\"MODO\"] = entrega[\"MODO\"]+1\n",
    "entrega[\"PRODUCCION\"]=entrega[\"PRODUCCION\"].round(2)\n",
    "entrega[\"SUPERFICIE\"]=entrega[\"SUPERFICIE\"].round(2)\n",
    "\n",
    "entrega.to_csv(\"SOFIS-ticados.txt\",index=False,header=False,sep = \"|\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
